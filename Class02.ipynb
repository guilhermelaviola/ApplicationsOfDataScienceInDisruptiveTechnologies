{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5NobcO1Z/izT/f4WSjFfa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/ApplicationsOfDataScienceInDisruptiveTechnologies/blob/main/Class02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Correlation-based algorithms**\n",
        "Uses statistical correlation to make decisions, such as in feature selection, where it identifies features most related to the target variable while minimizing redundancy between features. Other applications include pattern recognition in image processing, using correlation to find matching templates, and recommendation systems, using correlation to measure user or item similarity. These algorithms measure the relationship between two or more variables to identify similarities or differences."
      ],
      "metadata": {
        "id": "EVeMRbSdIcJ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "an0-qxDiHlZx"
      },
      "outputs": [],
      "source": [
        "# Importing all the necessary libraries:\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow  # to use cv2_imshow on Colab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display images in Colab:\n",
        "def display_image(frame):\n",
        "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Getting the name of the loaded video:\n",
        "video_path = list(uploaded.keys())[0]\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Reading the first video frame:\n",
        "ret, frame = cap.read()"
      ],
      "metadata": {
        "id": "Yp8iBwNUHzld",
        "outputId": "e601711d-38a9-4f0c-f86f-ef46fc8fe513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'uploaded' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1706384308.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Getting the name of the loaded video:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'uploaded' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Regression-based algorithms**\n",
        "Subset of machine learning algorithms that predict a continuous output variable based on one or more input features. Regression aims to model the relationship between the dependent variable (output) and one or more independent variables (inputs)."
      ],
      "metadata": {
        "id": "Rz4gMHnlIrdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display images in Colab:\n",
        "def display_image(frame):\n",
        "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Loading video with OpenCV:\n",
        "cap = cv2.VideoCapture('https://www.youtube.com/shorts/SxZJ4WWr6uE')  # Replace it with the video path"
      ],
      "metadata": {
        "id": "Qg7-fSx7I0_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the first frame of the video:\n",
        "ret, frame = cap.read()\n",
        "if not ret:\n",
        "    print('Error loading the video')\n",
        "else:\n",
        "    # Defining a Region of Interest (ROI) manually:\n",
        "    h, w, _ = frame.shape\n",
        "    roi = (int(w/4), int(h/4), int(w/2), int(h/2))  # ROI maior para rastreamento\n",
        "\n",
        "    # Displaying the first frame with the ROI:\n",
        "    p1 = (int(roi[0]), int(roi[1]))\n",
        "    p2 = (int(roi[0] + roi[2]), int(roi[1] + roi[3]))\n",
        "    cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
        "    exibir_imagem(frame)\n",
        "\n",
        "    # Initializing the MOSSE tracker:\n",
        "    tracker = cv2.legacy.TrackerMOSSE_create()\n",
        "\n",
        "    # Initializing the tracker with the first frame and ROI:\n",
        "    tracker.init(frame, roi)\n",
        "\n",
        "    # Tracking the object in the video:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Updating the tracker\n",
        "        ok, bbox = tracker.update(frame)\n",
        "\n",
        "        if ok:\n",
        "            # Drawing bounding box if tracking is successful:\n",
        "            p1 = (int(bbox[0]), int(bbox[1]))\n",
        "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
        "            cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
        "        else:\n",
        "            # Displaying tracking failure message:\n",
        "            cv2.putText(frame, 'Tracking failed', (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
        "\n",
        "        # Displaying the updated frame:\n",
        "        display_image(frame)\n",
        "\n",
        "    cap.release()"
      ],
      "metadata": {
        "id": "hl-TTHPdJIU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Optical Flow-Based Algorithms**\n",
        "Optical Flow is a way to analyze a scene and provide movement information, in the form of speed vectors (i.e. direction and amplitude). It is well known for frame-based cameras, but given this new event-based paradigm, we adopt new approaches to achieve this goal, while preserving the asynchronous nature of events."
      ],
      "metadata": {
        "id": "rEo9jrGLyaqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the video:\n",
        "cap = cv2.VideoCapture('video.avi')\n",
        "\n",
        "# Defining parameters for the Lucas-Kanade algorithm:\n",
        "lk_params = dict(winSize=(15, 15),\n",
        "                 maxLevel=2,\n",
        "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "# Generating some random colors to draw the trails:\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# Reading the first frame and detecting the points of interest:\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)"
      ],
      "metadata": {
        "id": "LOouMnKNyqwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an image mask to draw the trails:\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculating the optical flow:\n",
        "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
        "\n",
        "    # Selecting the good points:\n",
        "    good_new = p1[st == 1]\n",
        "    good_old = p0[st == 1]\n",
        "\n",
        "    # Drawing the trails:\n",
        "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "        a, b = new.ravel()\n",
        "        c, d = old.ravel()\n",
        "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
        "        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "\n",
        "    # Displaying the frame with the tracks:\n",
        "    cv2_imshow(img)\n",
        "\n",
        "    # Updating the parameters for the next frame:\n",
        "    old_gray = frame_gray.copy()\n",
        "    p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "T0EjUD_C1AEP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}