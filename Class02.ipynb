{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPM1DuSGKdDjAVgzRSACBZd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/ApplicationsOfDataScienceInDisruptiveTechnologies/blob/main/Class02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Object Tracking Algorithm Theory**\n",
        "Object tracking algorithm theory is a crucial area within computer vision, encompassing a variety of techniques that allow us to identify and track the trajectory of a moving object in a sequence of images or videos.\n",
        "This field is especially important in applications ranging from public safety to sports performance analysis. Understanding the different algorithms available and how they work is essential to choosing the right approach depending on the context in which you are working.\n",
        "To begin, it is important to consider the diversity of available algorithms. They can be classified into several categories, including correlation-based algorithms, regression algorithms, and algorithms that use optical flow. Each of these methods has unique characteristics that make them more or less suitable for certain situations. For example, when tracking a moving car on an urban street, an algorithm must be able to handle not only the vehicle's speed but also the presence of other cars and pedestrians."
      ],
      "metadata": {
        "id": "xpF8LyefQSbA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "an0-qxDiHlZx"
      },
      "outputs": [],
      "source": [
        "# Importing all the necessary libraries:\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow  # to use cv2_imshow on Colab\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Correlation-based algorithms**\n",
        "Uses statistical correlation to make decisions, such as in feature selection, where it identifies features most related to the target variable while minimizing redundancy between features. Other applications include pattern recognition in image processing, using correlation to find matching templates, and recommendation systems, using correlation to measure user or item similarity. These algorithms measure the relationship between two or more variables to identify similarities or differences."
      ],
      "metadata": {
        "id": "EVeMRbSdIcJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing video manually:\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Function to display images in Colab:\n",
        "def display_image(frame):\n",
        "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Getting the name of the loaded video:\n",
        "video_path = list(uploaded.keys())[0]\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Reading the first video frame:\n",
        "ret, frame = cap.read()"
      ],
      "metadata": {
        "id": "Yp8iBwNUHzld",
        "outputId": "90272f33-127d-40dc-eff6-e1bc30e74699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d7de367b-c745-4006-a8c5-c37bc82b0cd9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d7de367b-c745-4006-a8c5-c37bc82b0cd9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving madonna-live-to-tell-official-video-1986.mp4 to madonna-live-to-tell-official-video-1986.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Regression-based algorithms**\n",
        "Subset of machine learning algorithms that predict a continuous output variable based on one or more input features. Regression aims to model the relationship between the dependent variable (output) and one or more independent variables (inputs)."
      ],
      "metadata": {
        "id": "Rz4gMHnlIrdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display images in Colab:\n",
        "def display_image(frame):\n",
        "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Loading video with OpenCV:\n",
        "cap = cv2.VideoCapture('https://www.youtube.com/shorts/SxZJ4WWr6uE')  # Replace it with the video path\n",
        "\n",
        "# Reading the first frame of the video:\n",
        "ret, frame = cap.read()\n",
        "if not ret:\n",
        "    print('Error loading the video')\n",
        "else:\n",
        "    # Defining a Region of Interest (ROI) manually:\n",
        "    h, w, _ = frame.shape\n",
        "    roi = (int(w/4), int(h/4), int(w/2), int(h/2))  # ROI maior para rastreamento\n",
        "\n",
        "    # Displaying the first frame with the ROI:\n",
        "    p1 = (int(roi[0]), int(roi[1]))\n",
        "    p2 = (int(roi[0] + roi[2]), int(roi[1] + roi[3]))\n",
        "    cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
        "    exibir_imagem(frame)\n",
        "\n",
        "    # Initializing the MOSSE tracker:\n",
        "    tracker = cv2.legacy.TrackerMOSSE_create()\n",
        "\n",
        "    # Initializing the tracker with the first frame and ROI:\n",
        "    tracker.init(frame, roi)\n",
        "\n",
        "    # Tracking the object in the video:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Updating the tracker\n",
        "        ok, bbox = tracker.update(frame)\n",
        "\n",
        "        if ok:\n",
        "            # Drawing bounding box if tracking is successful:\n",
        "            p1 = (int(bbox[0]), int(bbox[1]))\n",
        "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
        "            cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
        "        else:\n",
        "            # Displaying tracking failure message:\n",
        "            cv2.putText(frame, 'Tracking failed', (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
        "\n",
        "        # Displaying the updated frame:\n",
        "        display_image(frame)\n",
        "\n",
        "    cap.release()"
      ],
      "metadata": {
        "id": "hl-TTHPdJIU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Optical Flow-Based Algorithms**\n",
        "Optical Flow is a way to analyze a scene and provide movement information, in the form of speed vectors (i.e. direction and amplitude). It is well known for frame-based cameras, but given this new event-based paradigm, we adopt new approaches to achieve this goal, while preserving the asynchronous nature of events."
      ],
      "metadata": {
        "id": "rEo9jrGLyaqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the video:\n",
        "cap = cv2.VideoCapture('video.avi')\n",
        "\n",
        "# Defining parameters for the Lucas-Kanade algorithm:\n",
        "lk_params = dict(winSize=(15, 15),\n",
        "                 maxLevel=2,\n",
        "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "# Generating some random colors to draw the trails:\n",
        "color = np.random.randint(0, 255, (100, 3))\n",
        "\n",
        "# Reading the first frame and detecting the points of interest:\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
        "\n",
        "# Creating an image mask to draw the trails:\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculating the optical flow:\n",
        "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
        "\n",
        "    # Selecting the good points:\n",
        "    good_new = p1[st == 1]\n",
        "    good_old = p0[st == 1]\n",
        "\n",
        "    # Drawing the trails:\n",
        "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "        a, b = new.ravel()\n",
        "        c, d = old.ravel()\n",
        "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
        "        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
        "\n",
        "    img = cv2.add(frame, mask)\n",
        "\n",
        "    # Displaying the frame with the tracks:\n",
        "    cv2_imshow(img)\n",
        "\n",
        "    # Updating the parameters for the next frame:\n",
        "    old_gray = frame_gray.copy()\n",
        "    p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "T0EjUD_C1AEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Performance Between Different Algorithms**"
      ],
      "metadata": {
        "id": "lu1jRTp870aC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the video:\n",
        "video_path = 'vtest.avi'\n",
        "\n",
        "# Function to measure tracking performance and calculate failures:\n",
        "def track_object(tracker_type):\n",
        "    # Initializing trackers according to their type:\n",
        "    if tracker_type == 'MOSSE':\n",
        "        tracker = cv2.legacy.TrackerMOSSE_create()\n",
        "    elif tracker_type == 'CSRT':\n",
        "        tracker = cv2.TrackerCSRT_create()\n",
        "    elif tracker_type == 'KCF':\n",
        "        tracker = cv2.TrackerKCF_create()\n",
        "\n",
        "    # Reading the video again:\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(f'Error loading the video with {tracker_type}')\n",
        "        return\n",
        "\n",
        "    # Defining the ROI (Region of Interest) manually:\n",
        "    h, w, _ = frame.shape\n",
        "    roi = (int(w/4), int(h/4), int(w/2), int(h/2))  # Bigger ROI\n",
        "\n",
        "    # Initializing the tracker within the first frame of the ROI:\n",
        "    tracker.init(frame, roi)\n",
        "\n",
        "    # Measuring tracking time and counting failures:\n",
        "    start_time = time.time()\n",
        "    errors = 0\n",
        "    total_frames = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        total_frames += 1\n",
        "\n",
        "        # Updating the tracker:\n",
        "        ok, bbox = tracker.update(frame)\n",
        "\n",
        "        if not ok:\n",
        "            falhas += 1\n",
        "\n",
        "    end_time = time.time()\n",
        "    diration = end_time - start_time\n",
        "\n",
        "    # Calcular a eficácia (percentual de rastreamento bem-sucedido)\n",
        "    eficacia = ((total_frames - falhas) / quadros_totais) * 100\n",
        "\n",
        "    # Exibir os resultados\n",
        "    print(f\"\\nAlgoritmo: {tracker_type}\")\n",
        "    print(f\"Tempo total: {duracao:.2f} segundos\")\n",
        "    print(f\"Falhas de rastreamento: {falhas}\")\n",
        "    print(f\"Eficácia de rastreamento: {eficacia:.2f}%\\n\")\n",
        "\n",
        "# Executar e comparar os três algoritmos\n",
        "for tracker_type in ['MOSSE', 'CSRT', 'KCF']:\n",
        "    print(f\"\\nExecutando rastreamento com {tracker_type}...\")\n",
        "    rastrear_objeto(tracker_type)"
      ],
      "metadata": {
        "id": "CX9qDWME7wbX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}