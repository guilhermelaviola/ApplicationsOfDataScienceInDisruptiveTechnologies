{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiMMYgJaftN9FMUY7eBARe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/ApplicationsOfDataScienceInDisruptiveTechnologies/blob/main/Class08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TLD (Tracking Learning Detection)**\n",
        "The TLD (Tracking Learning Detection) algorithm effectively addresses visual tracking challenges through its integration of tracking, learning, and detection processes. It predicts object movement using optical flow, updates appearance models continuously, and corrects tracking errors, enhancing robustness against complexities like occlusions and appearance changes. However, TLD requires considerable computational resources, which may limit its effectiveness on devices with lower capacity. Optimization strategies, including narrowing the search area and fine-tuning model updates, can reduce resource demands. Challenges such as drift, where background information can wrongly affect the appearance model, also need careful parameter adjustments and filtering techniques. Thus, while TLD is a potent solution for advanced visual tracking, its deployment requires judicious resource management and drift control."
      ],
      "metadata": {
        "id": "KSsOiTUaGt0z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dzEHF2GqGs19"
      },
      "outputs": [],
      "source": [
        "# Importing all the necessary libraries and resources:\n",
        "import cv2\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TLD example**"
      ],
      "metadata": {
        "id": "vtP0o4uvIJ6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading a video:\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Getting the title of the loaded video:\n",
        "video_path = next(iter(uploaded))\n",
        "\n",
        "# Loading the video:\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if the video was uploaded correctly:\n",
        "if not cap.isOpened():\n",
        "    print('Error loading the video.')\n",
        "else:\n",
        "    print('Video loaded successfully')\n",
        "\n",
        "# Reading the first name of the video:\n",
        "ret, frame = cap.read()\n",
        "\n",
        "if not ret:\n",
        "    print('Error reading the first frame of the video')\n",
        "else:\n",
        "    # Manually defining the ROI (Region of Interest):= instead of usding cv2.selectROI:\n",
        "    # bbox = (x, y, width, height)\n",
        "    bbox = (100, 100, 200, 200)  # Adjust these coordinates as needed for the video.\n",
        "\n",
        "    # Initializing the TLD tracker:\n",
        "    tracker = cv2.legacy.TrackerTLD_create()\n",
        "    tracker.init(frame, bbox)\n",
        "\n",
        "    print('TLD tracker initialized successfully!')\n",
        "\n",
        "# Loop to track the object through the video:\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Updating the tracking:\n",
        "    success, bbox = tracker.update(frame)\n",
        "\n",
        "    if success:\n",
        "        # Drawing the box around the tracked object:\n",
        "        p1 = (int(bbox[0]), int(bbox[1]))\n",
        "        p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
        "        cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
        "    else:\n",
        "        cv2.putText(frame, 'Tracking failed', (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
        "\n",
        "    # Displaying the frame with the bounding box in Google Colab:\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "__SFPTYQIRmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TLD Performance in Different Scenarios**"
      ],
      "metadata": {
        "id": "fy7OfexYIcPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading a video:\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Getting the title of the loaded video:\n",
        "video_path = next(iter(uploaded))\n",
        "\n",
        "# Loading the video:\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Check if the video was uploaded correctly:\n",
        "if not cap.isOpened():\n",
        "    print('Error loading the video.')\n",
        "else:\n",
        "    print('Video loaded successfully')\n",
        "\n",
        "# Reading the first name of the video:\n",
        "ret, frame = cap.read()\n",
        "\n",
        "if not ret:\n",
        "    print('Error reading the first frame of the video')\n",
        "else:\n",
        "    # Manually defining the ROI (Region of Interest):\n",
        "    # bbox = (x, y, width, height)\n",
        "    bbox = (100, 100, 200, 200)  # Adjusting as needed.\n",
        "\n",
        "    # Initializing the TLD tracker:\n",
        "    tracker = cv2.legacy.TrackerTLD_create()\n",
        "    tracker.init(frame, bbox)\n",
        "\n",
        "    print('TLD tracker initialized successfully!')\n",
        "\n",
        "# Loop to track the object through the video:\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Updating the tracking:\n",
        "    success, bbox = tracker.update(frame)\n",
        "\n",
        "    if success:\n",
        "        # Drawing the box around the tracked object:\n",
        "        p1 = (int(bbox[0]), int(bbox[1]))\n",
        "        p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
        "        cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
        "    else:\n",
        "        cv2.putText(frame, 'Tracking failed', (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
        "\n",
        "    # Displaying the frame with the bounding box in Google Colab:\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "5m_GghHqIpV6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}