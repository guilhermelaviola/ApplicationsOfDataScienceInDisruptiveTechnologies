{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIWPWMOPUt0BtVl54d8bdD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/ApplicationsOfDataScienceInDisruptiveTechnologies/blob/main/Class12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CAMShift (Continuously Adaptive Meanshift)**\n",
        "CAMShift, an advancement of the Meanshift algorithm, excels in object tracking within dynamic videos by continuously adjusting the tracking window's size to account for changes in scale, direction, and shape of moving objects. This adaptability makes it particularly effective in scenarios like sports, surveillance, and autonomous vehicles, where objects frequently move in and out of frame. Unlike Meanshift's fixed-size window, CAMShift recalibrates with each frame, enhancing accuracy in tracking objects, such as a soccer player whose movement varies greatly. The algorithm also employs the HSV color space for improved color detection under varying lighting conditions, and it can be combined with the Kalman Filter to maintain tracking when objects become temporarily obscured. Key implementation aspects include using computer vision libraries like OpenCV and applying techniques such as smoothing filters and initial region of interest (ROI) definition. Overall, CAMShift is recognized for its robustness and versatility across various applications, including security systems and motion analysis in sports and robotics."
      ],
      "metadata": {
        "id": "g9OAnK_31D8k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UdzrjcR51C4D"
      },
      "outputs": [],
      "source": [
        "# Importing all the necessary libraries:\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CAMShift on Google Colab**"
      ],
      "metadata": {
        "id": "TWXXHkGfCFBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to upload the video:\n",
        "uploaded = files.upload()\n",
        "video_filename = list(uploaded.keys())[0]  # Getting the name of the uploaded file.\n",
        "\n",
        "# Loading the user video:\n",
        "cap = cv2.VideoCapture(video_filename)\n",
        "# Checking if the video was properly loaded:\n",
        "if not cap.isOpened():\n",
        "    print('Error opening the video.')\n",
        "else:\n",
        "    # Capturing the first frame to define the ROI:\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        # Displaying the first frame:\n",
        "        cv2_imshow(frame)\n",
        "        # Converting the image to the HSV color space:\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "        # Defining the color range for detection (green as an example):\n",
        "        lower_green = np.array([40, 40, 40])\n",
        "        upper_green = np.array([80, 255, 255])\n",
        "        # Creating a mask to identify the green color:\n",
        "        mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "        # Finding contours in the mask:\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        # If contours found, defines the ROI based on the biggers contour:\n",
        "        if contours:\n",
        "            largest_contour = max(contours, key=cv2.contourArea)\n",
        "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "            roi = (x, y, w, h)\n",
        "            roi_hist = cv2.calcHist([frame[y:y+h, x:x+w]], [0, 1], None, [256, 256], [0, 180, 0, 256])\n",
        "            cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
        "        else:\n",
        "            print('No contour found. ROI not defined.')\n",
        "            cap.release()\n",
        "            exit()\n",
        "    else:\n",
        "        print('Error reading the first frame of the video.')\n",
        "\n",
        "# List to store the resulting frames:\n",
        "output_frames = []\n",
        "\n",
        "# Loop to track the video object:\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Converting to HSV color space:\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Calculating the probability of the new position:\n",
        "    back_project = cv2.calcBackProject([hsv], [0, 1], roi_hist, [0, 180, 0, 256], 1)\n",
        "\n",
        "    # Applying the CAMShift:\n",
        "    ret_val = cv2.CamShift(back_project, roi, (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1))\n",
        "\n",
        "    # Deconstructing the return of CamShift:\n",
        "    if ret_val is not None:\n",
        "        # The return value is a tuple containing the tracking box and the new ROI:\n",
        "        rotated_rect, track_window = ret_val\n",
        "\n",
        "        # Drawing the tracking box:\n",
        "        pts = cv2.boxPoints(rotated_rect)  # Using a RotatedRect directly:\n",
        "        pts = np.int32(pts)\n",
        "        cv2.polylines(frame, [pts], True, (255, 0, 0), 2)\n",
        "\n",
        "    # Adding the resulting frame to the list:\n",
        "    output_frames.append(frame)\n",
        "\n",
        "# Releasing the video:\n",
        "cap.release()\n",
        "\n",
        "# Displaying all resulting frames at the end:\n",
        "for output_frame in output_frames:\n",
        "    cv2_imshow(output_frame)"
      ],
      "metadata": {
        "id": "NI4j5YBj2CSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comparative Evaluation of CAMShift versus Meanshift**"
      ],
      "metadata": {
        "id": "duoLqNXeCL7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading the video:\n",
        "uploaded = files.upload()\n",
        "clear_output()  # Clearing the output for a cleaner interface.\n",
        "\n",
        "# Accessing the name of the file sent:\n",
        "video_path = next(iter(uploaded.keys()))\n",
        "\n",
        "# Capturing the loaded video:\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Reading the first frame and defining the ROI:\n",
        "ret, frame = cap.read()\n",
        "x, y, w, h = 300, 200, 100, 50  # ROI initial coordinates.\n",
        "roi = frame[y:y+h, x:x+w]\n",
        "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "roi_hist = cv2.calcHist([hsv_roi], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
        "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "# Function to apply CAMShift:\n",
        "def aplicar_camshift(cap, roi_hist):\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "    output_camshift = []\n",
        "    x, y, w, h = 300, 200, 100, 50\n",
        "    frame_count = 0  # Frame counter for sampling.\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret or frame_count > 100:  # Limiting to 100 frames.\n",
        "            break\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "        back_project = cv2.calcBackProject([hsv], [0, 1], roi_hist, [0, 180, 0, 256], 1)\n",
        "        ret_val = cv2.CamShift(back_project, (x, y, w, h), (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1))\n",
        "\n",
        "        if ret_val is not None:\n",
        "            rotated_rect, (x, y, w, h) = ret_val\n",
        "            pts = cv2.boxPoints(rotated_rect)\n",
        "            pts = np.int0(pts)\n",
        "            cv2.polylines(frame, [pts], True, (0, 0, 255), 2)\n",
        "\n",
        "        # Just add one out of every 10 processed frames:\n",
        "        if frame_count % 10 == 0:\n",
        "            output_camshift.append(frame)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    return output_camshift\n",
        "\n",
        "# Function to apply Meanshift:\n",
        "def aplicar_meanshift(cap, roi_hist):\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "    output_meanshift = []\n",
        "    x, y, w, h = 300, 200, 100, 50\n",
        "    frame_count = 0  # Frame counter for sampling.\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret or frame_count > 100:  # Limit to 100 frames.\n",
        "            break\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "        back_project = cv2.calcBackProject([hsv], [0, 1], roi_hist, [0, 180, 0, 256], 1)\n",
        "        _, (x, y, w, h) = cv2.meanShift(back_project, (x, y, w, h), (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1))\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "        # Just add one out of every 10 processed frames:\n",
        "        if frame_count % 10 == 0:\n",
        "            output_meanshift.append(frame)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    return output_meanshift\n",
        "\n",
        "# Executing both methods and store the resulting frames:\n",
        "output_camshift = aplicar_camshift(cap, roi_hist)\n",
        "output_meanshift = aplicar_meanshift(cap, roi_hist)\n",
        "\n",
        "# Releasing the video:\n",
        "cap.release()\n",
        "\n",
        "# Displaying the results for comparison:\n",
        "print('CAMShift results:')\n",
        "for frame in output_camshift:\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "print('Meanshift results:')\n",
        "for frame in output_meanshift:\n",
        "    cv2_imshow(frame)"
      ],
      "metadata": {
        "id": "ElRSs6cnB2CO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}