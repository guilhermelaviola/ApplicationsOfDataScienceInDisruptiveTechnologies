{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6B5F4TUJXBmu8r+Le99mE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/ApplicationsOfDataScienceInDisruptiveTechnologies/blob/main/Class07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MedianFlow**\n",
        "The MedianFlow algorithm is a video object tracking method that uses optical flow to accurately track object movement across frames based on pixel displacement, excelling in smooth movement situations. Its unique feature, bidirectional optical flow, aids in error correction. Unlike traditional average-based techniques, it applies median filtering to minimize noise effects, making it suitable for cluttered backgrounds. However, it faces challenges with rapid movements, occlusions, and varying object scales, as seen in fast-paced scenarios like soccer games. To improve its performance, combining MedianFlow with advanced algorithms such as KCF, along with image pre-processing and parameter optimization, is recommended. While effective in controlled settings, users must recognize its limitations for successful application."
      ],
      "metadata": {
        "id": "vNqwa96Mm2X0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the necessary libraries and resources:\n",
        "import cv2\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "jsg3xPzgmAWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MedianFlow example**"
      ],
      "metadata": {
        "id": "g5qZVHQTuWX3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAPPzEcIl5kx"
      },
      "outputs": [],
      "source": [
        "# Uploading the video:\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Getting the name of the loaded video:\n",
        "video_path = next(iter(uploaded))\n",
        "\n",
        "# Loading the video:\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Checking if the video was loaded correctly:\n",
        "if not cap.isOpened():\n",
        "    print('Error loading the video.')\n",
        "else:\n",
        "    # Reading the first frame of the video:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        print('Error reading the first frame.')\n",
        "    else:\n",
        "        # Adjusting the region of interest (ROI) to make it more accurate:\n",
        "        height, width, _ = frame.shape\n",
        "        bbox = (int(width * 0.3), int(height * 0.4), int(width * 0.4), int(height * 0.2))  # Adjustments based on the image proportions.\n",
        "\n",
        "        # Initializing the MedianFlow tracker using Legacy API, from OpenCV:\n",
        "        tracker = cv2.legacy.TrackerMedianFlow_create()\n",
        "        tracker.init(frame, bbox)\n",
        "\n",
        "        # Looping to track the object over the video:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Updating the tracking:\n",
        "            success, bbox = tracker.update(frame)\n",
        "\n",
        "            if success:\n",
        "                # Draw the box around the tracked object:\n",
        "                p1 = (int(bbox[0]), int(bbox[1]))\n",
        "                p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
        "                cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
        "            else:\n",
        "                cv2.putText(frame, 'Tracking failed', (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
        "\n",
        "            # Displayimg the frame with the bounding box in Google Colab:\n",
        "            cv2_imshow(frame)\n",
        "\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing the Robustness of MedianFlow**"
      ],
      "metadata": {
        "id": "XxNOmQ7Cuju7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-contrib-python\n",
        "!pip install --upgrade opencv-contrib-python-headless"
      ],
      "metadata": {
        "id": "kpyzEGzOuTD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading the video or image for tracking:\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Getting the name of the uploaded video:\n",
        "video_path = next(iter(uploaded))\n",
        "\n",
        "# Loading the video:\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Checking if the video was loaded correctly:\n",
        "if not cap.isOpened():\n",
        "    print('Error loading the video.')\n",
        "else:\n",
        "    # Reading the first frame of the video:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        print('Error reading the first frame of the video.')\n",
        "    else:\n",
        "        # Adjusting the region of interest (ROI) in a more precise way:\n",
        "        height, width, _ = frame.shape\n",
        "\n",
        "        # Defining the ROI based in the object closest possible location (in this example, it's the central area):\n",
        "        bbox = (int(width * 0.3), int(height * 0.3), int(width * 0.3), int(height * 0.3))\n",
        "\n",
        "        # Correcting the tracker to use the correct namespace:\n",
        "        tracker = cv2.legacy.TrackerMedianFlow_create()\n",
        "        tracker.init(frame, bbox)\n",
        "\n",
        "        # Loop to track the object over the video:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Updating the tracking:\n",
        "            success, bbox = tracker.update(frame)\n",
        "\n",
        "            if success:\n",
        "                # Drawing a box around the tracked object:\n",
        "                p1 = (int(bbox[0]), int(bbox[1]))\n",
        "                p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
        "                cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
        "            else:\n",
        "                cv2.putText(frame, 'Tracking failed', (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
        "\n",
        "            # Displaying the frame with the bounding box in Google Colab:\n",
        "            cv2_imshow(frame)\n",
        "\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "qLVaF0x9uTQw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}